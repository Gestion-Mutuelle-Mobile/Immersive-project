# ğŸ¥ Simulation MÃ©dicale Immersive 3D

## ğŸ“‹ Table des matiÃ¨res

- [Vue d'ensemble](#vue-densemble)
- [FonctionnalitÃ©s](#fonctionnalitÃ©s)
- [Technologies utilisÃ©es](#technologies-utilisÃ©es)
- [Architecture du projet](#architecture-du-projet)
- [Installation et configuration](#installation-et-configuration)
- [Synchronisation labiale - Guide technique dÃ©taillÃ©](#synchronisation-labiale---guide-technique-dÃ©taillÃ©)
- [Intelligence artificielle et gÃ©nÃ©ration vocale](#intelligence-artificielle-et-gÃ©nÃ©ration-vocale)
- [Interactions 3D et animations](#interactions-3d-et-animations)
- [Interface utilisateur mÃ©dicale](#interface-utilisateur-mÃ©dicale)
- [API et endpoints](#api-et-endpoints)
- [DÃ©bogage et dÃ©veloppement](#dÃ©bogage-et-dÃ©veloppement)
- [Performances et optimisations](#performances-et-optimisations)
- [Troubleshooting](#troubleshooting)
- [Roadmap et amÃ©liorations futures](#roadmap-et-amÃ©liorations-futures)

## Vue d'ensemble

La **Simulation MÃ©dicale Immersive 3D** est une application web avancÃ©e conÃ§ue pour former les Ã©tudiants en mÃ©decine Ã  travers des consultations virtuelles interactives. Le projet simule un patient virtuel en 3D capable de rÃ©pondre aux questions, rÃ©agir aux examens physiques et exprimer des symptÃ´mes de maniÃ¨re rÃ©aliste.

### ğŸ¯ Objectifs pÃ©dagogiques

- **Formation pratique** : Permettre aux Ã©tudiants de pratiquer les consultations mÃ©dicales sans risque
- **Interaction rÃ©aliste** : Simulations d'examens physiques avec retours appropriÃ©s
- **DiversitÃ© des cas** : DiffÃ©rents symptÃ´mes et pathologies simulÃ©s
- **Ã‰valuation continue** : Suivi des actions et dÃ©cisions des Ã©tudiants

### ğŸ—ï¸ Architecture technique

Le systÃ¨me repose sur une architecture client-serveur moderne :
- **Frontend** : React + Three.js pour la 3D immersive
- **Backend** : Node.js + Express pour l'orchestration
- **IA** : Google Gemini pour les rÃ©ponses contextuelles
- **Audio** : ElevenLabs pour la synthÃ¨se vocale
- **Synchronisation** : Rhubarb Lip Sync pour l'animation faciale

## FonctionnalitÃ©s

### ğŸ­ Patient virtuel intelligent
- **RÃ©ponses contextuelles** adaptÃ©es aux questions mÃ©dicales
- **Expressions faciales** dynamiques (douleur, inquiÃ©tude, surprise)
- **Animations corporelles** rÃ©alistes selon les symptÃ´mes
- **Synchronisation labiale** parfaite avec la parole

### ğŸ©º Examens physiques interactifs
- **Zones corporelles cliquables** (tÃªte, poitrine, abdomen, membres)
- **RÃ©actions appropriÃ©es** aux examens selon la zone touchÃ©e
- **Feedback visuel et audio** immÃ©diat
- **SystÃ¨me de cooldown** pour Ã©viter les interactions rÃ©pÃ©tÃ©es

### ğŸ’¬ Communication naturelle
- **Chat textuel** pour questions ouvertes
- **Commandes vocales** pour instructions directes
- **RÃ©ponses audio** avec synchronisation labiale
- **Interface multilingue** (franÃ§ais principalement)

### ğŸ¥ Environnement mÃ©dical
- **Salle de consultation** 3D modÃ©lisable
- **Outils mÃ©dicaux virtuels** (stÃ©thoscope, thermomÃ¨tre)
- **Interface diagnostique** pour prise de notes
- **Modes d'interaction** multiples

## Technologies utilisÃ©es

### Frontend (React + Three.js)

```json
{
  "dependencies": {
    "@react-three/drei": "9.75.0",
    "@react-three/fiber": "8.13.3", 
    "@react-three/xr": "^5.7.1",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "three": "0.153.0",
    "leva": "^0.9.35"
  }
}
```

**RÃ´les des principales bibliothÃ¨ques :**
- **@react-three/fiber** : Bridge React-Three.js pour composants 3D dÃ©claratifs
- **@react-three/drei** : Utilitaires et composants 3D prÃªts Ã  l'emploi
- **three** : Moteur 3D WebGL pour rendu et animations
- **leva** : Interface de contrÃ´le en temps rÃ©el pour dÃ©veloppement

### Backend (Node.js + IA)

```json
{
  "dependencies": {
    "@google/generative-ai": "^0.22.0",
    "elevenlabs-node": "latest",
    "express": "^4.18.0",
    "cors": "^2.8.5",
    "dotenv": "^16.0.0"
  }
}
```

**Services intÃ©grÃ©s :**
- **Google Gemini AI** : GÃ©nÃ©ration de rÃ©ponses contextuelles
- **ElevenLabs** : SynthÃ¨se vocale ultra-rÃ©aliste
- **Express** : Serveur HTTP et gestion des routes
- **FFmpeg** : Conversion et traitement audio
- **Rhubarb Lip Sync** : Analyse phonÃ©tique pour synchronisation

### Outils de dÃ©veloppement

- **Vite** : Build tool moderne et serveur de dÃ©veloppement
- **TailwindCSS** : Framework CSS utilitaire
- **PostCSS** : Traitement CSS avancÃ©
- **ESLint** : Linting et qualitÃ© de code

## Architecture du projet

```
tiger-foxx-my-ai-gf/
â”œâ”€â”€ README.md
â”œâ”€â”€ code-back/                    # Serveur Node.js
â”‚   â”œâ”€â”€ index.js                 # Point d'entrÃ©e du serveur
â”‚   â”œâ”€â”€ package.json             # DÃ©pendances backend
â”‚   â”œâ”€â”€ .env.example             # Variables d'environnement
â”‚   â””â”€â”€ audios/                  # Fichiers audio gÃ©nÃ©rÃ©s
â”‚       â”œâ”€â”€ message_*.mp3        # Audio synthÃ©tisÃ©
â”‚       â”œâ”€â”€ message_*.wav        # Audio converti
â”‚       â”œâ”€â”€ message_*.json       # DonnÃ©es de synchronisation
â”‚       â””â”€â”€ intro_*.wav          # Messages d'accueil
â””â”€â”€ code-front/                  # Application React
    â”œâ”€â”€ index.html               # Point d'entrÃ©e HTML
    â”œâ”€â”€ package.json             # DÃ©pendances frontend
    â”œâ”€â”€ vite.config.js           # Configuration Vite
    â”œâ”€â”€ tailwind.config.js       # Configuration TailwindCSS
    â”œâ”€â”€ public/                  # Assets statiques
    â”‚   â”œâ”€â”€ animations/          # Fichiers d'animation FBX
    â”‚   â”‚   â”œâ”€â”€ Idle.fbx
    â”‚   â”‚   â”œâ”€â”€ Talking_*.fbx
    â”‚   â”‚   â”œâ”€â”€ Angry.fbx
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â””â”€â”€ models/              # ModÃ¨les 3D
    â”‚       â”œâ”€â”€ 64f1a714fe61576b46f27ca2.glb  # ModÃ¨le patient
    â”‚       â”œâ”€â”€ animations.glb   # Animations compilÃ©es
    â”‚       â””â”€â”€ Salle.dae        # Environnement mÃ©dical
    â””â”€â”€ src/                     # Code source React
        â”œâ”€â”€ App.jsx              # Composant racine
        â”œâ”€â”€ main.jsx             # Point d'entrÃ©e React
        â”œâ”€â”€ index.css            # Styles globaux
        â”œâ”€â”€ components/          # Composants React
        â”‚   â”œâ”€â”€ Avatar.jsx       # Patient 3D principal
        â”‚   â”œâ”€â”€ Experience.jsx   # ScÃ¨ne 3D principale
        â”‚   â”œâ”€â”€ UI.jsx           # Interface utilisateur
        â”‚   â””â”€â”€ MedicalRoom.jsx  # Environnement mÃ©dical
        â””â”€â”€ hooks/               # Hooks React personnalisÃ©s
            â””â”€â”€ useChat.jsx      # Gestion de la communication
```

## Installation et configuration

### PrÃ©requis systÃ¨me

- **Node.js** â‰¥ 16.0.0
- **npm** ou **yarn**
- **FFmpeg** installÃ© et accessible via PATH
- **Rhubarb Lip Sync** installÃ© et accessible via PATH

### Installation de Rhubarb Lip Sync

#### Windows
```bash
# TÃ©lÃ©charger depuis https://github.com/DanielSWolf/rhubarb-lip-sync/releases
# Extraire et ajouter au PATH
```

#### macOS
```bash
brew install rhubarb-lip-sync
```

#### Linux
```bash
# Compiler depuis les sources ou utiliser AppImage
wget https://github.com/DanielSWolf/rhubarb-lip-sync/releases/download/v1.13.0/Rhubarb-Lip-Sync-1.13.0-Linux.zip
```

### Installation du projet

1. **Cloner le repository**
```bash
git clone <repository-url>
cd tiger-foxx-my-ai-gf
```

2. **Configuration du backend**
```bash
cd code-back
npm install

# CrÃ©er le fichier .env
cp .env.example .env
```

3. **Variables d'environnement (.env)**
```env
# ClÃ© API Google Gemini
GEMINI_API_KEY=votre_clÃ©_gemini_ici

# ClÃ© API ElevenLabs
ELEVEN_LABS_API_KEY=sk_votre_clÃ©_elevenlabs_ici

# Configuration serveur
PORT=3000
NODE_ENV=development
```

4. **Configuration du frontend**
```bash
cd ../code-front
npm install

# CrÃ©er le fichier d'environnement local
echo "VITE_API_URL=http://localhost:3000" > .env.local
```

5. **DÃ©marrage en dÃ©veloppement**

Terminal 1 (Backend) :
```bash
cd code-back
npm start
```

Terminal 2 (Frontend) :
```bash
cd code-front
npm run dev
```

L'application sera accessible sur `http://localhost:5173`

## Synchronisation labiale - Guide technique dÃ©taillÃ©

La synchronisation labiale est l'une des fonctionnalitÃ©s les plus complexes et impressionnantes du projet. Elle permet au patient virtuel de "parler" de maniÃ¨re naturelle en synchronisant les mouvements de bouche avec l'audio.

### ğŸ”§ Pipeline de traitement

#### 1. GÃ©nÃ©ration de l'audio (ElevenLabs)

```javascript
// Backend : index.js
await voice.textToSpeech(elevenLabsApiKey, voiceID, fileName, message.text, {
  model_id: "eleven_multilingual_v2",
  voice_settings: {
    stability: 0.5,
    similarity_boost: 0.8,
    style: 0.2
  }
});
```

**ParamÃ¨tres optimisÃ©s :**
- **model_id** : `eleven_multilingual_v2` pour supporter le franÃ§ais
- **stability** : 0.5 pour Ã©quilibre naturalitÃ©/cohÃ©rence
- **similarity_boost** : 0.8 pour maintenir la voix du personnage
- **style** : 0.2 pour lÃ©gÃ¨re expressivitÃ© Ã©motionnelle

#### 2. Conversion audio (FFmpeg)

```javascript
// Conversion MP3 â†’ WAV pour Rhubarb
await execCommand(
  `ffmpeg -y -i audios/message_${message}.mp3 audios/message_${message}.wav`
);
```

**Pourquoi cette conversion ?**
- Rhubarb nÃ©cessite des fichiers WAV non compressÃ©s
- Meilleure prÃ©cision d'analyse phonÃ©tique
- Format standardisÃ© pour tous les traitements

#### 3. Analyse phonÃ©tique (Rhubarb Lip Sync)

```javascript
// GÃ©nÃ©ration des donnÃ©es de synchronisation
await execCommand(
  `rhubarb -f json -o audios/message_${message}.json audios/message_${message}.wav -r phonetic`
);
```

**Options Rhubarb expliquÃ©es :**
- **-f json** : Format de sortie JSON pour intÃ©gration web
- **-o** : Fichier de sortie pour les donnÃ©es
- **-r phonetic** : Mode d'analyse phonÃ©tique (vs PocketSphinx)

#### 4. Structure des donnÃ©es gÃ©nÃ©rÃ©es

```json
{
  "metadata": {
    "soundFile": "message_0.wav",
    "duration": 2.34
  },
  "mouthCues": [
    {
      "start": 0.00,
      "end": 0.13,
      "value": "X"
    },
    {
      "start": 0.13, 
      "end": 0.26,
      "value": "B"
    },
    {
      "start": 0.26,
      "end": 0.41,
      "value": "C"
    }
  ]
}
```

**Signification des valeurs :**
- **start/end** : Timestamps en secondes
- **value** : PhonÃ¨me correspondant (A, B, C, D, E, F, G, H, X)

### ğŸ¯ Mapping phonÃ©tique â†’ VisÃ¨mes

Les phonÃ¨mes de Rhubarb sont mappÃ©s vers les visÃ¨mes (positions de bouche) du modÃ¨le 3D :

```javascript
// Avatar.jsx - Correspondance phonÃ¨me â†’ visÃ¨me
const corresponding = {
  A: "viseme_PP",    // Voyelles fermÃ©es (papa, mama)
  B: "viseme_kk",    // Consonnes occlusives (k, g, ng)
  C: "viseme_I",     // Voyelles antÃ©rieures (eat, bit)
  D: "viseme_AA",    // Voyelles ouvertes (car, lot)
  E: "viseme_O",     // Voyelles arrondies (you, book)
  F: "viseme_U",     // Voyelles fermÃ©es arrondies
  G: "viseme_FF",    // Fricatives labiodentales (f, v)
  H: "viseme_TH",    // Fricatives dentales (th)
  X: "viseme_PP"     // Silence / transitions
};
```

### âš¡ Rendu temps rÃ©el

La synchronisation est appliquÃ©e dans la boucle de rendu Three.js :

```javascript
// Avatar.jsx - useFrame hook
useFrame(() => {
  // ... autres animations ...

  const appliedMorphTargets = [];
  if (message && lipsync && currentAudio) {
    const currentAudioTime = currentAudio.currentTime;
    
    // Parcourir tous les phonÃ¨mes
    for (let i = 0; i < lipsync.mouthCues.length; i++) {
      const mouthCue = lipsync.mouthCues[i];
      
      // VÃ©rifier si nous sommes dans la fenÃªtre temporelle
      if (currentAudioTime >= mouthCue.start && 
          currentAudioTime <= mouthCue.end) {
        
        // Appliquer le visÃ¨me correspondant
        appliedMorphTargets.push(corresponding[mouthCue.value]);
        lerpMorphTarget(corresponding[mouthCue.value], 1, 0.2);
        break;
      }
    }
  }

  // RÃ©initialiser les autres visÃ¨mes
  Object.values(corresponding).forEach((value) => {
    if (appliedMorphTargets.includes(value)) {
      return;
    }
    lerpMorphTarget(value, 0, 0.1);
  });
});
```

### ğŸ”„ Interpolation des morphs

```javascript
// Fonction d'interpolation douce des targets
const lerpMorphTarget = (target, value, speed = 0.1) => {
  scene.traverse((child) => {
    if (child.isSkinnedMesh && child.morphTargetDictionary) {
      const index = child.morphTargetDictionary[target];
      if (index === undefined || 
          child.morphTargetInfluences[index] === undefined) {
        return;
      }
      
      // Interpolation linÃ©aire pour transition douce
      child.morphTargetInfluences[index] = THREE.MathUtils.lerp(
        child.morphTargetInfluences[index],
        value,
        speed
      );
    }
  });
};
```

**ParamÃ¨tres d'interpolation :**
- **speed = 0.2** : Activation rapide du visÃ¨me
- **speed = 0.1** : DÃ©sactivation plus lente pour naturel

### ğŸ­ ModÃ¨le 3D et morphing

Le modÃ¨le 3D du patient utilise des **blend shapes** (morphing) :

```javascript
// Structure des morphTargets dans le modÃ¨le GLB
morphTargetDictionary: {
  "viseme_PP": 0,
  "viseme_kk": 1, 
  "viseme_I": 2,
  "viseme_AA": 3,
  "viseme_O": 4,
  "viseme_U": 5,
  "viseme_FF": 6,
  "viseme_TH": 7,
  // ... autres expressions faciales
}
```

### ğŸ“Š MÃ©triques de performance

**Latence typique du pipeline :**
- GÃ©nÃ©ration audio ElevenLabs : ~2-5 secondes
- Conversion FFmpeg : ~100-300ms
- Analyse Rhubarb : ~200-500ms
- **Total** : ~3-6 secondes selon la longueur

**Optimisations implÃ©mentÃ©es :**
- Cache des fichiers audio gÃ©nÃ©rÃ©s
- Traitement asynchrone non-bloquant
- Interpolation optimisÃ©e en GPU
- PrÃ©chargement des assets 3D

### ğŸ› Debugging de la synchronisation

**ContrÃ´les de dÃ©veloppement disponibles :**

```javascript
// ContrÃ´les Leva pour debug
useControls("Lipsync Debug", {
  "Audio Time": { value: audioTime, disabled: true },
  "Current Phoneme": { value: currentPhoneme, disabled: true },
  "Active Visemes": { value: activeVisemes, disabled: true }
});
```

**Logs de diagnostic :**
```javascript
console.log(`ğŸµ Audio: ${currentAudioTime.toFixed(2)}s`);
console.log(`ğŸ“± PhonÃ¨me actuel: ${mouthCue.value}`);
console.log(`ğŸ‘„ VisÃ¨me appliquÃ©: ${corresponding[mouthCue.value]}`);
```

### âš ï¸ Limitations et solutions

**ProblÃ¨mes courants :**

1. **DÃ©calage audio/visuel**
    - **Cause** : Latence de dÃ©marrage audio navigateur
    - **Solution** : Calibrage automatique +50ms

2. **PhonÃ¨mes manquÃ©s**
    - **Cause** : Analyse Rhubarb imprÃ©cise
    - **Solution** : Fallback sur phonÃ¨me prÃ©cÃ©dent

3. **Transitions brusques**
    - **Cause** : Vitesse d'interpolation trop Ã©levÃ©e
    - **Solution** : Ajustement dynamique selon BPM

## Intelligence artificielle et gÃ©nÃ©ration vocale

### ğŸ¤– Google Gemini Integration

Le systÃ¨me utilise Gemini 1.5 Flash pour gÃ©nÃ©rer des rÃ©ponses contextuelles de patient :

```javascript
// Configuration du modÃ¨le IA
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
```

### ğŸ“ Prompt Engineering mÃ©dical

```javascript
const medicalPrompt = `Tu es un patient virtuel dans une simulation mÃ©dicale pour former de jeunes mÃ©decins.

CONTEXTE: Tu es un patient de 35 ans qui consulte pour des maux de tÃªte, de la fatigue et des douleurs diverses. Tu es inquiet mais coopÃ©ratif.

IMPORTANT: RÃ©ponds STRICTEMENT en JSON avec ce format :
{
  "messages": [
    {
      "text": "ta rÃ©ponse de patient",
      "facialExpression": "expression",
      "animation": "animation"
    }
  ]
}

Expressions/Animations disponibles :
- facialExpression: smile, sad, angry, surprised, funnyFace, default, worried, pain
- animation: Talking_0, Talking_1, Talking_2, Crying, Laughing, Idle, Terrified, Angry

COMPORTEMENT:
- Parle comme un vrai patient franÃ§ais
- Montre de l'inquiÃ©tude pour ta santÃ©
- Sois coopÃ©ratif avec le mÃ©decin
- DÃ©cris tes symptÃ´mes de faÃ§on rÃ©aliste
- Utilise des expressions appropriÃ©es (worried/pain pour les douleurs, surprised pour les examens, etc.)

Message du mÃ©decin : "${userMessage}"`;
```

### ğŸ¤ ElevenLabs Voice Synthesis

**Configuration optimisÃ©e pour le franÃ§ais :**

```javascript
await voice.textToSpeech(elevenLabsApiKey, voiceID, fileName, message.text, {
  model_id: "eleven_multilingual_v2", // Support multilingue
  voice_settings: {
    stability: 0.5,        // Ã‰quilibre cohÃ©rence/naturalitÃ©
    similarity_boost: 0.8, // Maintien du caractÃ¨re vocal
    style: 0.2,           // ExpressivitÃ© Ã©motionnelle lÃ©gÃ¨re
    use_speaker_boost: true // AmÃ©lioration de la clartÃ©
  }
});
```

## Interactions 3D et animations

### ğŸ¯ SystÃ¨me de dÃ©tection tactile

Le systÃ¨me utilise le raycasting Three.js pour dÃ©tecter les clics sur le modÃ¨le 3D :

```javascript
const handleClick = (event) => {
  event.stopPropagation();

  // Configuration du raycaster
  raycaster.setFromCamera(pointer, camera);
  const intersects = raycaster.intersectObjects(scene.children, true);

  if (intersects.length > 0) {
    const clickedObject = intersects[0].object;
    const bodyPart = identifyBodyPart(clickedObject, intersects[0].point);
    
    // DÃ©clencher la rÃ©action appropriÃ©e
    handlePatientTouch(bodyPart);
  }
};
```

### ğŸ—ºï¸ Mapping anatomique

```javascript
// Identification intelligente des parties du corps
const identifyBodyPart = (object, point) => {
  const objectName = object.name.toLowerCase();
  const position = point;

  // Identification par nom d'objet
  if (objectName.includes('head') || objectName.includes('hair') || 
      objectName.includes('eye') || objectName.includes('teeth')) {
    return 'head';
  }
  
  // Identification par position spatiale
  if (objectName.includes('body') || objectName.includes('outfit_top')) {
    return position.y > 1.3 ? 'chest' : 'abdomen';
  }

  // Fallback par position Y
  if (position.y > 1.5) return 'head';
  if (position.y > 1.2) return 'chest';
  if (position.y > 0.8) return 'abdomen';
  return 'feet';
};
```

### ğŸ­ SystÃ¨me d'animations

**Gestion des animations Three.js :**

```javascript
const { actions, mixer } = useAnimations(animations, group);

useEffect(() => {
  if (actions[animation]) {
    try {
      actions[animation]
        .reset()
        .fadeIn(mixer.stats.actions.inUse === 0 ? 0 : 0.5)
        .play();
      
      return () => {
        if (actions[animation]) {
          actions[animation].fadeOut(0.5);
        }
      };
    } catch (error) {
      console.warn(`Animation ${animation} problÃ©matique:`, error);
      // Fallback vers animation sÃ»re
      if (animation !== "Idle") {
        setAnimation("Idle");
      }
    }
  }
}, [animation, actions]);
```

**Animations disponibles :**
- **Idle** : Position repos naturelle
- **Talking_0/1/2** : Variations de conversation
- **Crying** : Expression de douleur intense
- **Angry** : RÃ©action d'inconfort
- **Terrified** : Surprise ou peur
- **Laughing** : DÃ©tente ou soulagement

### â±ï¸ SystÃ¨me de cooldown

```javascript
// PrÃ©vention des interactions rÃ©pÃ©tÃ©es
const [touchInteractionCooldown, setTouchInteractionCooldown] = useState(false);

const handlePatientTouch = (bodyPart) => {
  if (touchInteractionCooldown || loading) {
    return; // Ignorer si en cooldown
  }

  setTouchInteractionCooldown(true);
  
  // Traitement de l'interaction...
  
  // Cooldown de 3 secondes
  setTimeout(() => {
    setTouchInteractionCooldown(false);
  }, 3000);
};
```

## Interface utilisateur mÃ©dicale

### ğŸ¥ Design systÃ¨me mÃ©dical

L'interface utilise TailwindCSS avec une palette mÃ©dicale professionnelle :

```css
/* Couleurs principales */
--medical-blue: #2563eb;
--medical-green: #10b981;
--medical-red: #ef4444;
--medical-gray: #6b7280;
--background-medical: #f8fafc;
```

### ğŸ“± Composants d'interface

#### Panel de consultation

```jsx
<div className="fixed left-4 top-1/2 transform -translate-y-1/2 backdrop-blur-md bg-white bg-opacity-90 p-4 rounded-lg pointer-events-auto max-w-xs">
  {/* Onglets de navigation */}
  <div className="flex gap-2 mb-4">
    <button onClick={() => setActiveTab("consultation")} 
            className={`px-3 py-1 rounded text-sm font-medium ${
              activeTab === "consultation" ? "bg-blue-500 text-white" : "bg-gray-200"
            }`}>
      Consultation
    </button>
    {/* ... autres onglets */}
  </div>
  
  {/* Contenu contextuel */}
  {activeTab === "consultation" && <ConsultationPanel />}
  {activeTab === "examination" && <ExaminationPanel />}
  {activeTab === "diagnostic" && <DiagnosticPanel />}
</div>
```

#### Commandes rapides mÃ©dicales

```jsx
const medicalCommands = [
  { text: "Bonjour, comment vous sentez-vous aujourd'hui ?", type: "greeting" },
  { text: "Pouvez-vous me dÃ©crire vos symptÃ´mes ?", type: "question" },
  { text: "Depuis quand ressentez-vous ces douleurs ?", type: "question" },
  { text: "Levez-vous s'il vous plaÃ®t", type: "command" },
  { text: "Respirez profondÃ©ment", type: "command" },
  { text: "Toussez pour moi", type: "command" }
];
```

### ğŸ® ContrÃ´les interactifs

#### Modes d'interaction

```jsx
const [interactionMode, setInteractionMode] = useState("voice");

// Basculement entre modes
<button onClick={() => setInteractionMode(mode === "voice" ? "chat" : "voice")}>
  {interactionMode === "voice" ? "ğŸ¤ Commandes vocales" : "ğŸ’¬ Chat normal"}
</button>
```

#### Zones d'examen corporel

```jsx
const bodyParts = [
  { name: "TÃªte", id: "head", icon: "ğŸ§ " },
  { name: "Poitrine", id: "chest", icon: "ğŸ«" },
  { name: "Abdomen", id: "abdomen", icon: "ğŸ¤±" },
  { name: "Bras gauche", id: "left_arm", icon: "ğŸ’ª" },
  { name: "Bras droit", id: "right_arm", icon: "ğŸ’ª" },
  { name: "Jambe gauche", id: "left_leg", icon: "ğŸ¦µ" },
  { name: "Jambe droite", id: "right_leg", icon: "ğŸ¦µ" }
];
```

### ğŸ“Š Indicateurs de statut

```jsx
const PatientStatusIndicator = () => {
  const { patientState, loading, message } = useChat();
  
  const getStatusInfo = () => {
    if (loading) return { text: "RÃ©flexion...", color: "#f59e0b" };
    if (message) return { text: "Parle...", color: "#10b981" };
    
    switch(patientState) {
      case 'sitting': return { text: "Assis", color: "#3b82f6" };
      case 'lying': return { text: "AllongÃ©", color: "#8b5cf6" };
      case 'walking': return { text: "Debout", color: "#f97316" };
      default: return { text: "Au repos", color: "#6b7280" };
    }
  };
  
  return (
    <div className="status-indicator">
      <Text color={status.color}>Ã‰tat: {status.text}</Text>
    </div>
  );
};
```

## API et endpoints

### ğŸŒ Routes principales

#### POST /chat
**Conversation principale avec le patient**

```javascript
app.post("/chat", async (req, res) => {
  const userMessage = req.body.message;
  
  // Validation
  if (!userMessage) {
    return res.send({ messages: defaultWelcomeMessages });
  }
  
  // GÃ©nÃ©ration IA
  const prompt = buildMedicalPrompt(userMessage);
  const aiResponse = await model.generateContent(prompt);
  
  // Traitement audio et synchronisation
  const messages = await processAudioSync(aiResponse);
  
  res.send({ messages });
});
```

#### POST /medical-command
**Commandes mÃ©dicales directes**

```javascript
app.post("/medical-command", async (req, res) => {
  const command = req.body.command;
  
  // Traitement des commandes spÃ©ciales
  if (isSpecialCommand(command)) {
    return res.send({ messages: handleSpecialCommand(command) });
  }
  
  // Redirection vers chat normal
  req.body.message = command;
  return handleChat(req, res);
});
```

#### GET /voices
**Liste des voix disponibles ElevenLabs**

```javascript
app.get("/voices", async (req, res) => {
  try {
    const voices = await voice.getVoices(elevenLabsApiKey);
    res.send(voices);
  } catch (error) {
    res.status(500).send({ error: "Erreur rÃ©cupÃ©ration voix" });
  }
});
```

### ğŸ“¡ Gestion des erreurs

```javascript
// Middleware de gestion d'erreurs global
app.use((error, req, res, next) => {
  console.error('Erreur serveur:', error);
  
  if (error.name === 'ValidationError') {
    return res.status(400).send({ error: 'DonnÃ©es invalides' });
  }
  
  if (error.code === 'ENOTFOUND') {
    return res.status(503).send({ error: 'Service externe indisponible' });
  }
  
  res.status(500).send({ 
    error: 'Erreur interne du serveur',
    fallback: generateFallbackResponse()
  });
});
```

### ğŸ” SÃ©curitÃ© et validation

```javascript
// Validation des entrÃ©es
const validateMessage = (message) => {
  if (!message || typeof message !== 'string') {
    throw new Error('Message invalide');
  }
  
  if (message.length > 1000) {
    throw new Error('Message trop long');
  }
  
  // Filtrage contenu inappropriÃ©
  if (containsInappropriateContent(message)) {
    throw new Error('Contenu non autorisÃ©');
  }
  
  return true;
};
```

## DÃ©bogage et dÃ©veloppement

### ğŸ› ï¸ ContrÃ´les Leva

Le systÃ¨me inclut des contrÃ´les de dÃ©veloppement exhaustifs :

```javascript
// ContrÃ´les expressions faciales
useControls("FacialExpressions", {
  chat: button(() => chat("Test message")),
  "Clin d'Å“il gauche": button(() => triggerWink("left")),
  "Clin d'Å“il droit": button(() => triggerWink("right")),
  animation: {
    value: animation,
    options: animations.map(a => a.name),
    onChange: setAnimation
  },
  facialExpression: {
    value: facialExpression,
    options: Object.keys(facialExpressions),
    onChange: setFacialExpression
  }
});

// ContrÃ´les de morphing dÃ©taillÃ©s
useControls("MorphTarget", () =>
  Object.assign({},
    ...Object.keys(morphTargetDictionary).map(key => ({
      [key]: {
        label: key,
        value: 0,
        min: 0,
        max: 1,
        onChange: (val) => lerpMorphTarget(key, val, 1)
      }
    }))
  )
);

// Debug synchronisation labiale
useControls("Lipsync Debug", {
  "Audio Time": { value: audioTime, disabled: true },
  "Current Phoneme": { value: currentPhoneme, disabled: true },
  "Viseme Active": { value: activeViseme, disabled: true },
  "Manual Sync": button(() => testLipsync())
});

// ContrÃ´les salle mÃ©dicale
useControls("ğŸ¥ Salle MÃ©dicale", {
  showRoom: { value: true, label: "Afficher la salle" },
  roomScale: { value: 1, min: 0.1, max: 3, step: 0.1 },
  roomPositionX: { value: 0, min: -10, max: 10, step: 0.1 },
  roomPositionY: { value: 0, min: -5, max: 5, step: 0.1 },
  roomPositionZ: { value: 0, min: -10, max: 10, step: 0.1 },
  roomRotationY: { value: 0, min: -Math.PI, max: Math.PI, step: 0.1 }
});
```

### ğŸ“Š Logging systÃ¨me

```javascript
// Logger configurÃ© pour dÃ©veloppement
const Logger = {
  info: (msg, data) => console.log(`â„¹ï¸  ${msg}`, data),
  warn: (msg, data) => console.warn(`âš ï¸  ${msg}`, data),
  error: (msg, error) => console.error(`âŒ ${msg}`, error),
  debug: (msg, data) => {
    if (process.env.NODE_ENV === 'development') {
      console.debug(`ğŸ› ${msg}`, data);
    }
  },
  
  // Logs spÃ©cialisÃ©s
  audio: (msg, data) => console.log(`ğŸ”Š ${msg}`, data),
  ai: (msg, data) => console.log(`ğŸ¤– ${msg}`, data),
  interaction: (msg, data) => console.log(`ğŸ‘† ${msg}`, data),
  animation: (msg, data) => console.log(`ğŸ­ ${msg}`, data)
};
```

### ğŸ” Performance monitoring

```javascript
// MÃ©triques de performance
const PerformanceMonitor = {
  startTimer: (label) => {
    console.time(label);
    return label;
  },
  
  endTimer: (label) => {
    console.timeEnd(label);
  },
  
  measureAudioGeneration: async (fn) => {
    const start = performance.now();
    const result = await fn();
    const end = performance.now();
    
    Logger.audio(`GÃ©nÃ©ration audio: ${(end - start).toFixed(2)}ms`);
    return result;
  },
  
  measureLipsyncProcessing: async (fn) => {
    const start = performance.now();
    const result = await fn();
    const end = performance.now();
    
    Logger.debug(`Traitement lipsync: ${(end - start).toFixed(2)}ms`);
    return result;
  }
};
```

## Performances et optimisations

### âš¡ Optimisations Three.js

```javascript
// Configuration du renderer pour performance
const renderer = new THREE.WebGLRenderer({
  canvas: canvasRef.current,
  antialias: true,
  alpha: true,
  powerPreference: "high-performance"
});

// Optimisations de rendu
renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
renderer.shadowMap.enabled = true;
renderer.shadowMap.type = THREE.PCFSoftShadowMap;
renderer.outputEncoding = THREE.sRGBEncoding;
renderer.toneMapping = THREE.ACESFilmicToneMapping;
```

### ğŸš€ Optimisations audio

```javascript
// Cache audio pour Ã©viter rÃ©gÃ©nÃ©ration
const audioCache = new Map();

const getCachedAudio = async (text, voiceSettings) => {
  const cacheKey = `${text}_${JSON.stringify(voiceSettings)}`;
  
  if (audioCache.has(cacheKey)) {
    return audioCache.get(cacheKey);
  }
  
  const audio = await generateAudio(text, voiceSettings);
  audioCache.set(cacheKey, audio);
  
  return audio;
};
```

### ğŸ’¾ Gestion mÃ©moire

```javascript
// Nettoyage automatique des assets
useEffect(() => {
  return () => {
    // Nettoyage audio
    if (currentAudio) {
      currentAudio.pause();
      currentAudio.src = '';
    }
    
    // Nettoyage Three.js
    if (scene) {
      scene.traverse((child) => {
        if (child.geometry) child.geometry.dispose();
        if (child.material) {
          if (Array.isArray(child.material)) {
            child.material.forEach(material => material.dispose());
          } else {
            child.material.dispose();
          }
        }
      });
    }
    
    // Nettoyage timeouts
    clearAllTimeouts();
  };
}, []);
```

### ğŸ“ˆ MÃ©triques de performance

**Objectifs de performance :**
- **Temps de rÃ©ponse IA** : < 3 secondes
- **GÃ©nÃ©ration audio** : < 5 secondes
- **FPS 3D** : > 30 FPS constant
- **Latence interaction** : < 100ms
- **MÃ©moire utilisÃ©e** : < 500MB

**Monitoring automatique :**
```javascript
// Monitoring FPS
let frameCount = 0;
let lastTime = performance.now();

const monitorFPS = () => {
  frameCount++;
  const currentTime = performance.now();
  
  if (currentTime - lastTime >= 1000) {
    const fps = Math.round((frameCount * 1000) / (currentTime - lastTime));
    Logger.debug(`FPS: ${fps}`);
    
    if (fps < 30) {
      Logger.warn(`Performance dÃ©gradÃ©e: ${fps} FPS`);
    }
    
    frameCount = 0;
    lastTime = currentTime;
  }
};
```

## Troubleshooting

### âŒ ProblÃ¨mes courants

#### 1. Audio ne se lit pas / double lecture

**Causes possibles :**
- Gestion multiple de `onended`
- Autoplay bloquÃ© par le navigateur
- Conflits entre instances audio

**Solutions :**
```javascript
// Solution 1: Gestion unique de onended
useEffect(() => {
  if (!message?.audio) return;
  
  const audio = new Audio("data:audio/mp3;base64=" + message.audio);
  setCurrentAudio(audio);
  
  // UNE SEULE gestion de fin
  audio.onended = () => {
    setCurrentAudio(null);
    onMessagePlayed(); // Une seule fois
  };
  
  audio.play().catch(console.error);
}, [message]); // PAS onMessagePlayed dans deps

// Solution 2: Forcer interaction utilisateur
const enableAudio = () => {
  const dummy = new Audio();
  dummy.play().then(() => dummy.pause());
};
```

#### 2. Synchronisation labiale dÃ©calÃ©e

**Diagnostic :**
```javascript
// VÃ©rifier timing
console.log({
  audioTime: audio.currentTime,
  expectedPhoneme: getCurrentExpectedPhoneme(),
  actualViseme: getCurrentViseme()
});
```

**Correction calibrage :**
```javascript
// Ajustement offset
const LIPSYNC_OFFSET = 0.05; // 50ms d'avance
const adjustedTime = audio.currentTime + LIPSYNC_OFFSET;
```

#### 3. Interactions ne fonctionnent plus

**VÃ©rifications :**
```javascript
// Debug Ã©tat interaction
console.log({
  touchInteractionCooldown,
  loading,
  message: !!message,
  canInteract: !touchInteractionCooldown && !loading && !message
});
```

#### 4. Animations cassÃ©es / T-pose

**Causes :**
- Animation inexistante dans le fichier GLB
- Conflit entre animations
- ProblÃ¨me de skeleton

**Solution :**
```javascript
// VÃ©rification sÃ©curisÃ©e
const setAnimationSafe = (animationName) => {
  if (actions[animationName]) {
    setAnimation(animationName);
  } else {
    console.warn(`Animation ${animationName} non trouvÃ©e, fallback vers Idle`);
    setAnimation("Idle");
  }
};
```

#### 5. Erreurs console Three.js PropertyBinding

**Cause :** Animations avec rÃ©fÃ©rences vers bones inexistants

**Solution :**
```javascript
// Ignorer erreurs non-critiques
const originalConsoleError = console.error;
console.error = (...args) => {
  if (args[0]?.includes?.('PropertyBinding') && 
      args[0]?.includes?.('wasn\'t found')) {
    return; // Ignorer ces erreurs spÃ©cifiques
  }
  originalConsoleError.apply(console, args);
};
```

### ğŸ”§ Scripts de diagnostic

```bash
# VÃ©rification dÃ©pendances audio
npm run check-audio-deps

# Test pipeline complet
npm run test-pipeline

# Diagnostic modÃ¨les 3D
npm run validate-models

# Nettoyage cache
npm run clean-cache
```

### ğŸ“ Support technique

**Informations Ã  fournir :**
1. Version navigateur et OS
2. Messages d'erreur console complets
3. Configuration GPU (chrome://gpu)
4. Logs serveur backend
5. Ã‰tapes de reproduction

## Roadmap et amÃ©liorations futures

### ğŸ¯ Version 2.0 - AmÃ©liorations prÃ©vues

#### ğŸ¥ FonctionnalitÃ©s mÃ©dicales avancÃ©es

- **Pathologies multiples** : Simulation de cas complexes
- **Examens spÃ©cialisÃ©s** : Auscultation, palpation, rÃ©flexes
- **Outils mÃ©dicaux** : StÃ©thoscope, tensiomÃ¨tre, otoscope interactifs
- **Historique mÃ©dical** : Dossier patient complet et Ã©volutif

#### ğŸ¤– Intelligence artificielle

- **ModÃ¨les spÃ©cialisÃ©s** : Formation sur corpus mÃ©dical
- **PersonnalitÃ©s patients** : DiffÃ©rents profils psychologiques
- **Apprentissage adaptatif** : IA qui s'amÃ©liore selon les interactions
- **Diagnostic assistant** : Aide au diagnostic pour l'Ã©tudiant

#### ğŸ­ Rendu et interactions

- **ModÃ¨les haute rÃ©solution** : Avatars ultra-rÃ©alistes
- **Physiologie avancÃ©e** : Rougeur, transpiration, tremblements
- **Haptique** : Retour tactile pour examens
- **Eye tracking** : Suivi du regard pour interactions naturelles

#### ğŸŒ Collaboration et Ã©valuation

- **Mode multi-utilisateur** : Consultations en Ã©quipe
- **Enregistrement sessions** : Replay et analyse
- **Ã‰valuation automatique** : Scoring des performances
- **ScÃ©narios scriptÃ©s** : Cas d'Ã©tude structurÃ©s

### ğŸ”® Vision long terme

#### IntÃ©gration AR/VR
```javascript
// PrÃ©paration WebXR
import { VRButton, ARButton, XR } from '@react-three/xr';

export const MedicalSimulationVR = () => {
  return (
    <XR>
      <VRButton />
      <Canvas>
        <Experience />
      </Canvas>
    </XR>
  );
};
```

#### IA mÃ©dicale spÃ©cialisÃ©e
- **Diagnostic assistant** basÃ© sur symptÃ´mes
- **Base de connaissances** mÃ©dicale intÃ©grÃ©e
- **Simulation pathologies** rares
- **Formation continue** adaptative

#### Ã‰cosystÃ¨me Ã©ducatif
- **LMS intÃ©grÃ©** pour cursus mÃ©dical
- **Certification** des compÃ©tences
- **Analytics** d'apprentissage
- **CommunautÃ©** d'Ã©tudiants et formateurs

